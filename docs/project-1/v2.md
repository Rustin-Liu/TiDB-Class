# Project-1: 归并排序V2

### 2.0 二路归并排序

#### 2.1 Bench 数据对比

[v2.0代码提交历史](https://github.com/Rustin-Liu/TiDB-Class/commit/3ce6769743d50c17e838bff7b9640e846410ec0c)

cmd: `go test -bench .`

- BenchmarkMergeSort:   23102889277 ns/op
- BenchmarkNormalSort:  4009473899 ns/op

#### 2.2 内存和 CPU 分析

cmd: `go test -bench . -version v2.0`

##### 1.2.1 CPU

|     top     | Flat  |  Flat% |  Sum%  |   Cum  |  Cum%  |      Name        |
| ----------- | ----- | ------ | ------ | ------ | ------ | ---------------- |
|      1      | 9.44s | 16.63% | 16.63% | 9.44s  | 16.63% | runtime.madvise  |
|      2      | 6.78s | 11.95% | 28.58% | 14.21s | 25.04% | mergesort.merge  |

- **分析**：
    1. 大量的调用 runtime.madvise。
    ```go
    188        .          .     func madvise(addr unsafe.Pointer, n uintptr, flags int32) { 
    189        .          .         libcCall(unsafe.Pointer(funcPC(madvise_trampoline)), unsafe.Pointer(&addr)) 
    190    9.44s      9.44s     } 
    ```

    2. 临时变量 b 的初始化和分配调用耗时, 如果使用全局变量需要加锁，可能效果会更差。
    ```go
    34         .      7.43s     b := make([]int64, lb) 
    ```
- **优化**：
    1. 因为目前的这个代码每次分治都要去创建 goroutine, 并且大量使用 WaitGroup 花了大量时间在 allocSpanLocked 上面。直接使用通道可能会好点。
    2. 如果使用全局变量加锁效果可能也不是特别好。

##### 2.2.2 Mem
- **分析**：
    1. 临时变量 b 的大量分配。
    ```go
    34       1.60GB     1.60GB           	b := make([]int64, lb)
    ```
- **优化**：
    1. 如果使用全局变量加锁效果可能也不是特别好。

#### 2.3 优化迭代至 v2.3

[v2.1代码提交历史](https://github.com/Rustin-Liu/TiDB-Class/commit/1e6807ce92306d9f4d93cc0f39a6fc026e4defcf)
[v2.2代码提交历史](https://github.com/Rustin-Liu/TiDB-Class/commit/997112711f21934bc3ef81d9528041c22306ddcc)

cmd: `go test -bench .`

- BenchmarkMergeSort:   1619055231 ns/op
- BenchmarkNormalSort:  3884959740 ns/op

- **Code Change**
    ```go
    func parallelMergeSort(src []int64, lo int64, hi int64, semaphore chan struct{}) {
        // 多线程和单线程结合
        if hi-lo < 2 {
            return
        }
    
        mi := (lo + hi) / 2
    
        wg := sync.WaitGroup{}
        wg.Add(2)
    
        select {
        case semaphore <- struct{}{}:
            go func() {
                parallelMergeSort(src, lo, mi, semaphore)
                <-semaphore
                wg.Done()
            }()
        default:
            mergeSort(src, lo, mi)
            wg.Done()
        }
    
        select {
        case semaphore <- struct{}{}:
            go func() {
                parallelMergeSort(src, mi, hi, semaphore)
                <-semaphore
                wg.Done()
            }()
        default:
            mergeSort(src, mi, hi)
            wg.Done()
        }
    
        wg.Wait()
        merge(src, lo, mi, hi)
    }
    ```

- **优化结果分析**：

    在2.1版本中我使用通道来做，但是实际上的效果也很差，核心的原因还是浪费了大量的时间和内存在创建 go 程上。

    在2.2版本中我将 go 程减半，但是效果依旧不理想。

    在2.3的这版中，我采用信号量控制 go 程个数，也结合单线程的一起使用，大幅度的提升了性能。
    ```go
    188        .          .      func madvise(addr unsafe.Pointer, n uintptr, flags int32) { 
    189        .          .        libcCall(unsafe.Pointer(funcPC(madvise_trampoline)), unsafe.Pointer(&addr)) 
    190    450ms      450ms      }   // 显著减少
    ```

#### 参考文档
[Goroutines on Mergesort](https://medium.com/@yliu224/goroutines-on-mergesort-12a2a7a43cc2)